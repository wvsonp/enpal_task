{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Lifecycle Demo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "from IPython.display import display"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1. Train and log models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/ces00/enpal/enpal_2/.venv/lib/python3.13/site-packages/mlflow/types/utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
            "  warnings.warn(\n",
            "2026/02/27 18:48:45 WARNING mlflow.sklearn: Saving scikit-learn models in the pickle or cloudpickle format requires exercising caution because these formats rely on Python's object serialization mechanism, which can execute arbitrary code during deserialization. The recommended safe alternative is the 'skops' format. For more information, see: https://scikit-learn.org/stable/model_persistence.html\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Run ID: 18ee196876a94e619f535f8c87502f3c\n",
            "Model version: 2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Registered model 'churn-predictor' already exists. Creating a new version of this model...\n",
            "Created version '2' of model 'churn-predictor'.\n"
          ]
        }
      ],
      "source": [
        "from src.train import train_and_evaluate\n",
        "from src.mlflow_wrapper import log_run, set_model_alias\n",
        "\n",
        "MODEL_NAME = \"churn-predictor\"\n",
        "CSV_PATH = \"data/WA_Fn-UseC_-Telco-Customer-C.csv\" # as if: FS.get_features()\n",
        "\n",
        "result = train_and_evaluate(CSV_PATH, random_state=42)\n",
        "model_version = log_run(result, MODEL_NAME)\n",
        "set_model_alias(MODEL_NAME, int(model_version.version)) # Simulate the promotion pipeline step\n",
        "\n",
        "print(\"Run ID:\", model_version.run_id)\n",
        "print(\"Model version:\", model_version.version)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2. Load champion and infer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>MonthlyCharges</th>\n",
              "      <th>tenure</th>\n",
              "      <th>TotalCharges</th>\n",
              "      <th>HighValueFiber</th>\n",
              "      <th>predicted_churn</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2481</th>\n",
              "      <td>25.00</td>\n",
              "      <td>61</td>\n",
              "      <td>1501.75</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6784</th>\n",
              "      <td>24.70</td>\n",
              "      <td>19</td>\n",
              "      <td>465.85</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6125</th>\n",
              "      <td>102.25</td>\n",
              "      <td>13</td>\n",
              "      <td>1359.00</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3052</th>\n",
              "      <td>55.05</td>\n",
              "      <td>37</td>\n",
              "      <td>2030.75</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4099</th>\n",
              "      <td>29.45</td>\n",
              "      <td>6</td>\n",
              "      <td>161.45</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      MonthlyCharges  tenure  TotalCharges  HighValueFiber  predicted_churn\n",
              "2481           25.00      61       1501.75               0                0\n",
              "6784           24.70      19        465.85               0                0\n",
              "6125          102.25      13       1359.00               1                1\n",
              "3052           55.05      37       2030.75               0                0\n",
              "4099           29.45       6        161.45               0                0"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from src.mlflow_wrapper import load_champion\n",
        "\n",
        "MODEL_NAME = \"churn-predictor\"\n",
        "\n",
        "model = load_champion(MODEL_NAME) # simulate deployment step\n",
        "example = result[\"X_test\"].head(5)\n",
        "predictions = model.predict(example) # simulate inference step\n",
        "display(example.assign(predicted_churn=predictions))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3. Show metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>run_id</th>\n",
              "      <th>status</th>\n",
              "      <th>metrics.precision</th>\n",
              "      <th>metrics.accuracy</th>\n",
              "      <th>metrics.recall</th>\n",
              "      <th>metrics.f1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>18ee196876a94e619f535f8c87502f3c</td>\n",
              "      <td>FINISHED</td>\n",
              "      <td>0.55082</td>\n",
              "      <td>0.756219</td>\n",
              "      <td>0.449198</td>\n",
              "      <td>0.494845</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>50887a29492447a8be905f6018976c57</td>\n",
              "      <td>FINISHED</td>\n",
              "      <td>0.55082</td>\n",
              "      <td>0.756219</td>\n",
              "      <td>0.449198</td>\n",
              "      <td>0.494845</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                             run_id    status  metrics.precision  \\\n",
              "0  18ee196876a94e619f535f8c87502f3c  FINISHED            0.55082   \n",
              "1  50887a29492447a8be905f6018976c57  FINISHED            0.55082   \n",
              "\n",
              "   metrics.accuracy  metrics.recall  metrics.f1  \n",
              "0          0.756219        0.449198    0.494845  \n",
              "1          0.756219        0.449198    0.494845  "
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from mlflow.tracking.fluent import search_runs\n",
        "import pandas as pd\n",
        "from src.mlflow_wrapper import load_config\n",
        "\n",
        "load_config()\n",
        "runs = search_runs(output_format=\"pandas\")\n",
        "assert isinstance(runs, pd.DataFrame)\n",
        "cols = [c for c in runs.columns if c.startswith(\"metrics.\")]\n",
        "runs[[\"run_id\", \"status\"] + cols].head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
